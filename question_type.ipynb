{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what contemptible scoundrel stole the cork fro...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what team did baseball 's st. louis browns bec...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is the oldest profession ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what are liver enzymes ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>name the scar-faced bounty hunter of the old w...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question category\n",
       "0  how did serfdom develop in and then leave russ...  unknown\n",
       "1  what films featured the character popeye doyle ?      what\n",
       "2  how can i find a list of celebrities ' real na...  unknown\n",
       "3  what fowl grabs the spotlight after the chines...     what\n",
       "4                   what is the full form of .com ?      what\n",
       "5  what contemptible scoundrel stole the cork fro...     what\n",
       "6  what team did baseball 's st. louis browns bec...     what\n",
       "7                   what is the oldest profession ?      what\n",
       "8                          what are liver enzymes ?      what\n",
       "9  name the scar-faced bounty hunter of the old w...  unknown"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['question', 'category']\n",
    "df = pd.read_csv('/Users/moukthika/Desktop/questions.csv', names = col_names)\n",
    "df.head(10)\n",
    "\n",
    "#what the data contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what time of day did emperor hirohito die ?  : when\n"
     ]
    }
   ],
   "source": [
    "#Printing only the first few rows. On closer look of the  data we see that \"What time\" type sentences have been categorised under\n",
    "#\"when\" instead of \"what\" and it makes sense because \"what time\" or \"what year\" correspond to temporal events that can be \n",
    "#addressed by \"when\"\n",
    "#so the data contains some ambiguity. \n",
    "\n",
    "print( df.question[395], \":\", df.category[395])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAGkCAYAAAD+P2YmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4NJbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe58ef70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('category').question.count().plot.bar(ylim=0)\n",
    "plt.show()\n",
    "\n",
    "#Visualising the data with respect to the category the questions have to be classified into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre processing the data before vectorising it.\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def preprocessing(string):\n",
    "    words = nltk.word_tokenize(string) #splitting the sentences into words\n",
    "    words = [w.lower() for w in words] #converting all words to lower case to avoid have separate vectors for words such as \"now\" and \"Now\" i\n",
    "    words = [word for word in words if word.isalpha()] #removing everything that is not alphabetic to get rid of punctuations.\n",
    "    \n",
    "    \n",
    "    #stop_words = stopwords.words('english')\n",
    "    #words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    #stop_words contain words like \"when\", \"what\", \"how\", auxilaries and modal auxilaries that are used in forming questions\n",
    "    #so getting rid of them will fail the purpose of the model. \n",
    "    \n",
    "    stemmed = [porter.stem(word) for word in words] #to reduce the word to it's root/base. Since we are not looking at a deeper meaning of a word here and want to reduce the vocanulary size.\n",
    "    words = stemmed\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 85)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since we cannot work with text directly for ML algorithms, the text has to be converted to meaninful numbers. \n",
    "#One way of doing it is with Bag of Words model.\n",
    "#In Bag of Words model one can get rid of the sequential data (which is language) and only focus on the word occurances, \n",
    "#Tfidf is one type of Bag of Words model. \n",
    "#This is an acronym than stands for “Term Frequency – Inverse Document” Frequency which are the components of the resulting scores assigned to each word.\n",
    "#Term Frequency: This summarizes how often a given word appears within a document.\n",
    "#Inverse Document Frequency: This downscales words that appear a lot across documents.\n",
    "\n",
    "#From the visual above, we clearly have a class imbalance, i.e there are more 'what' type sentences than 'when' or 'affirmation'\n",
    "#Well the inverse document frequency of 'what' will be very low (because it is found in most documents), \n",
    "#so the feature 'what' will get a very small TFIDF, which is the weight of the feature used by the classifier.\n",
    "#TF-IDF are word frequency scores that try to highlight words that are more interesting, \n",
    "#e.g. frequent in a document but not across documents.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=10, max_df = 15, norm='l2', encoding='latin-1', ngram_range=(1,3), tokenizer = preprocessing)\n",
    "#the n-gram range is between 1 and 3 i.e the vectors of unigrams, bigrams and trigrams will be generated\n",
    "#this is important here because we want to work around ambiguity. Using only unigrams would not work as well as using bigrams where\n",
    "#we can capture \"what time\" or \"what time does\" together instead of \"what\" spearately. \n",
    "\n",
    "features = tfidf.fit_transform(df.question).toarray() #the tfidf vectors of the questions will serve as features\n",
    "labels = df.category\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting the test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['question'], df['category'], random_state = 42, test_size = 0.2)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                \"\"\"Using Naive Bayes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB(alpha = 1.0)\n",
    "clf_nb = model_nb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83164983165\n"
     ]
    }
   ],
   "source": [
    "prediction_nb =  clf_nb.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what']\n"
     ]
    }
   ],
   "source": [
    "#not a great accuracy and \"when\" is being identified as \"what\"\n",
    "print(clf_nb.predict(count_vect.transform([\"when are you going?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                    \"\"\"Using SVM\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm = svm.LinearSVC()\n",
    "clf_svm = model_svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952861952862\n"
     ]
    }
   ],
   "source": [
    "prediction_svm = clf_svm.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what']\n",
      "['what']\n",
      "['what']\n",
      "['what']\n",
      "['unknown']\n",
      "['who']\n",
      "['what']\n",
      "['when']\n",
      "['what']\n",
      "['what']\n",
      "['what']\n",
      "['affirmation']\n"
     ]
    }
   ],
   "source": [
    "#the accuracy is quite good\n",
    "#and the data is being classified into the right category(at least superficially), but this is not what we really want.\n",
    "print(clf_svm.predict(count_vect.transform([\"what time can you reach?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what time will you reach?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what day is your birthday?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what time will your bring it?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"How did serfdom develop in and then leave Russia ?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"Who followed Caesar ?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"What college produced the most winning Super Bowl quarterbacks ?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\" When did the Dow first reach ?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what time will is your train?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what time is the lecture starting?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"what time is her interview?\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"will you take me to the town?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                    \"\"\"Using SGD\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moukthika\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42) \n",
    "sgd_clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939393939394\n"
     ]
    }
   ],
   "source": [
    "#less accurate than SVM\n",
    "prediction_sgd = sgd_clf.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what']\n"
     ]
    }
   ],
   "source": [
    "print(sgd_clf.predict(count_vect.transform([\"what time can you reach?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                \"\"\"Random Forest\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model_rc=RandomForestClassifier(n_estimators=100, random_state = 42)\n",
    "model_rc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949494949495\n"
     ]
    }
   ],
   "source": [
    "#better accuracy than SGD but not SVM\n",
    "#and the prediction made for \"what time\" is correct in 2 cases here.\n",
    "prediction_rc = model_rc.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when']\n",
      "['what']\n",
      "['when']\n",
      "['unknown']\n",
      "['who']\n",
      "['what']\n",
      "['when']\n",
      "['what']\n",
      "['what']\n",
      "['what']\n",
      "['affirmation']\n"
     ]
    }
   ],
   "source": [
    "print(model_rc.predict(count_vect.transform([\"what time will you reach?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"what day is your birthday?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"what time will your bring it?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"How did serfdom develop in and then leave Russia ?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"Who followed Caesar ?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"What college produced the most winning Super Bowl quarterbacks ?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\" When did the Dow first reach ?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"what time will is your train?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"what time is the lecture starting?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"what time is her interview?\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"will you take me to the town?\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                            \"\"\"Decision Tree\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model_dt=tree.DecisionTreeClassifier()\n",
    "model_dt.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "#the accuray is poor\n",
    "#however, \"what-time\" is being categorized very well! The classifier however is not very good with affirmations. \n",
    "prediction_dt = model_dt.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when']\n",
      "['when']\n",
      "['when']\n",
      "['when']\n",
      "['what']\n",
      "['when']\n",
      "['unknown']\n",
      "['who']\n",
      "['what']\n",
      "['when']\n",
      "['when']\n",
      "['when']\n",
      "['when']\n",
      "['unknown']\n",
      "['affirmation']\n",
      "['affirmation']\n",
      "['unknown']\n",
      "['unknown']\n",
      "['unknown']\n"
     ]
    }
   ],
   "source": [
    "print(model_dt.predict(count_vect.transform([\"what time will you go?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time is your interview?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time is the match starting?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time will you reach?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what day is your birthday?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time will your bring it?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"How did serfdom develop in and then leave Russia ?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"Who followed Caesar ?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"What college produced the most winning Super Bowl quarterbacks ?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\" When did the Dow first reach ?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time will is your train?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time is the lecture starting?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"what time is her interview?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"will you take me to the town?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"can you put 100 chocolates in that small cover?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"how are you doing this evening little girl?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"will you put 100 chocolates in that small cover?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"will the night be aware of the danger?\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"will you take me to the kingdom?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                    \"\"\"KNeighbours\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828282828283\n"
     ]
    }
   ],
   "source": [
    "#the accuracy is not even as good as Naive Bayes'\n",
    "# the prediction for the sentence is also not great. \n",
    "prediction_knn = clf_knn.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affirmation']\n"
     ]
    }
   ],
   "source": [
    "print(clf_knn.predict(count_vect.transform([\"what time is it?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                \"\"\"Extra Tree Classifier\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf_etc = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "min_samples_split=2, random_state=0)\n",
    "clf_etc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929292929293\n"
     ]
    }
   ],
   "source": [
    "#accuracy not as good\n",
    "#but \"what time\" labelled correctly\n",
    "prediction_etc = clf_etc.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when']\n",
      "['what']\n",
      "['what']\n"
     ]
    }
   ],
   "source": [
    "print(clf_etc.predict(count_vect.transform([\"what time will you go?\"])))\n",
    "print(clf_etc.predict(count_vect.transform([\"what time is your interview?\"])))\n",
    "print(clf_etc.predict(count_vect.transform([\"what time is the match starting?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                            \"\"\"Voting Classifier\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=[3, 1])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to combine the best of decision tree and svm\n",
    "vc = VotingClassifier(estimators=[('dt',model_dt),('svm',clf_svm)],\n",
    "                        voting='hard',\n",
    "                        weights=[3,1])\n",
    "vc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882154882155\n"
     ]
    }
   ],
   "source": [
    "prediction_vc= vc.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when']\n",
      "['when']\n",
      "['when']\n",
      "['who']\n",
      "['what']\n",
      "['when']\n"
     ]
    }
   ],
   "source": [
    "print(vc.predict(count_vect.transform([\"what time will you go?\"])))\n",
    "print(vc.predict(count_vect.transform([\"what time is your interview?\"])))\n",
    "print(vc.predict(count_vect.transform([\"what time is the match starting?\"])))\n",
    "print(vc.predict(count_vect.transform([\"Who followed Caesar ?\"])))\n",
    "print(vc.predict(count_vect.transform([\"What college produced the most winning Super Bowl quarterbacks ?\"])))\n",
    "print(vc.predict(count_vect.transform([\" When did the Dow first reach ?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Of all the models SVM has highest accuracy(95.28) followed by Random Forest(94.49). However, when it comesto handling the ambiguities, \n",
    "such as \"what time\" for \"when\", Random Forest does better. The good performance of random forests could be due to that it is an \n",
    "ensemble technique and ensemble techniques perform well with data having imbalanced classes such as ours.\n",
    "\n",
    "However, Random Forests are known to reduce in performance when the data is much larger and sparse.\n",
    "\n",
    "The decision tree classifier on the other hand is modelling the ambiguity presented by \"what time\" well despite a low accuracy,\n",
    "the low accuracy could be due to it's miscategorization of few affirmative questions, such as those startimg with 'will' \n",
    "\n",
    "Random Forests seem to be performing optimally, with good accuracy and also identifying ambiguity.\n",
    "\n",
    "An ensemble of decision tree and svm gives an accuracy of 88. One should tweak the weights to either get a high overall accuracy\n",
    "or to be able to classify ambiguities. \n",
    "\n",
    "One can thus choose their classifier depending on the need. \"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
